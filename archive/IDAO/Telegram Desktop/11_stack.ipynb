{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:02.306177Z",
     "start_time": "2018-04-03T15:10:00.233160Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "from scipy.optimize import minimize, fmin_slsqp\n",
    "from datetime import date, timedelta\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:02.493569Z",
     "start_time": "2018-04-03T15:10:02.311929Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:02.513190Z",
     "start_time": "2018-04-03T15:10:02.502952Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:02.645973Z",
     "start_time": "2018-04-03T15:10:02.523381Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:06.093640Z",
     "start_time": "2018-04-03T15:10:05.714591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 337 ms, sys: 36.8 ms, total: 374 ms\n",
      "Wall time: 370 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train and sub format already merged with weather and holidays (plus the day before holiday)\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:07.022120Z",
     "start_time": "2018-04-03T15:10:07.013737Z"
    }
   },
   "outputs": [],
   "source": [
    "train.columns = ['Timestamp','ForecastId','Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:09.007917Z",
     "start_time": "2018-04-03T15:10:08.969826Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_preprocess(X):\n",
    "    X['Timestamp'] = pd.to_datetime(X['Timestamp'])\n",
    "    X['year'] = X['Timestamp'].dt.year\n",
    "    X['month'] = X['Timestamp'].dt.month \n",
    "    X['day'] = X['Timestamp'].dt.day\n",
    "    X['week_day'] = X['Timestamp'].dt.weekday\n",
    "    X['hour'] = X['Timestamp'].dt.hour\n",
    "    X['minute'] = X['Timestamp'].dt.minute\n",
    "    X['minute'] = X['minute'] // 15 * 15\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:10.328100Z",
     "start_time": "2018-04-03T15:10:09.823399Z"
    }
   },
   "outputs": [],
   "source": [
    "train = time_preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:10.395382Z",
     "start_time": "2018-04-03T15:10:10.334258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>Value</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week_day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>91600</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>136500</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>335400</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>379000</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>344100</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp  ForecastId   Value  year  month  day  week_day  hour  minute\n",
       "0 2015-01-01           0   91600  2015      1    1         3     0       0\n",
       "1 2015-01-02           0  136500  2015      1    2         4     0       0\n",
       "2 2015-01-03           0  335400  2015      1    3         5     0       0\n",
       "3 2015-01-04           0  379000  2015      1    4         6     0       0\n",
       "4 2015-01-05           0  344100  2015      1    5         0     0       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:12.812059Z",
     "start_time": "2018-04-03T15:10:12.635249Z"
    }
   },
   "outputs": [],
   "source": [
    "def MeanEncodingTransforming(X, y, X_test, how_to_fill):\n",
    "    \n",
    "    # mean encoding for lgb\n",
    "    \n",
    "    X_train = pd.concat([X, y], axis=1)\n",
    "    mean_values = X_train.groupby(X_train.columns[0]).agg(how_to_fill).to_dict()['Value']\n",
    "    X_train = X_train.drop(y.columns[0], axis=1)\n",
    "    X_train = X_train.replace(mean_values)\n",
    "    X_test = X_test.replace(mean_values)\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def feature_preprocessing(train, test, cat_cols, cat_type='ohe'):\n",
    "    \n",
    "    # ohe or mean encoding preprocessing for the lgb \n",
    "    \n",
    "    X_train, X_test = train[cat_cols].copy(), test[cat_cols].copy()\n",
    "\n",
    "    if (cat_type=='mean_enc'):\n",
    "        for j in ['mean', 'max', 'min', 'median']:\n",
    "            for i in cat_cols:\n",
    "                X_train[i], X_test[i] = MeanEncodingTransforming(X_train[i], train[['Value']], X_test[i], j)\n",
    "                X_train[i].columns = [i+'_'+j]\n",
    "                X_test[i].columns = [i+'_'+j]\n",
    "                \n",
    "    if (cat_type=='ohe'):\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        X_train = ohe.fit_transform(train[cat_cols])\n",
    "        X_test = ohe.transform(test[cat_cols])\n",
    "        X_train = pd.DataFrame(X_train)\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "    return X_train, X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:13.953919Z",
     "start_time": "2018-04-03T15:10:13.745454Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_groupby(train, test, window, how):\n",
    "    \n",
    "    # simple groupby prediction \n",
    "    \n",
    "    time_delta = list((test['Timestamp'].iloc[-1:]  - train['Timestamp'].iloc[1] ).dt.days)[0]\n",
    "    \n",
    "    if (time_delta < 21):\n",
    "        mean_values = train[['Value', 'hour', 'minute']][-window:].groupby(['hour', 'minute']).agg(how).reset_index()\n",
    "        mean_values.columns = ['hour','minute', 'pred']\n",
    "        test = pd.merge(test, mean_values, how='left', on = ['hour','minute'])\n",
    "        \n",
    "    if ((time_delta >=21) & (time_delta < 365)):\n",
    "        mean_values = train[['Value', 'week_day', 'hour', 'minute']][-window:].groupby(['week_day', 'hour', 'minute']).agg(how).reset_index()\n",
    "        mean_values.columns = ['week_day','hour','minute', 'pred']\n",
    "        test = pd.merge(test, mean_values, how='left', on = ['week_day','hour','minute'])  \n",
    "        \n",
    "    if ( time_delta >=365 ):\n",
    "        mean_values = train[['Value', 'month', 'week_day', 'hour', 'minute']][-window:].groupby(['month', 'week_day', 'hour', 'minute']).agg(how).reset_index()\n",
    "        mean_values.columns = ['month', 'week_day','hour','minute', 'pred']\n",
    "        test = pd.merge(test, mean_values, how='left', on = ['month', 'week_day','hour','minute'])  \n",
    "\n",
    "    if (np.sum(test['pred'].isnull()) / len(test) > 0.3):\n",
    "        test = test.drop('pred',axis=1)\n",
    "        mean_values = train[['Value', 'hour', 'minute']][-window:].groupby(['hour', 'minute']).agg(how).reset_index()\n",
    "        mean_values.columns = ['hour','minute', 'pred']\n",
    "        test = pd.merge(test, mean_values, how='left', on = ['hour','minute'])\n",
    "    \n",
    "    return test['pred'].fillna(np.mean(train['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:14.469631Z",
     "start_time": "2018-04-03T15:10:14.455752Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_mean(train, window):\n",
    "    \n",
    "    # return mean value from train for the window \n",
    "    \n",
    "    mean_value = np.mean(train['Value'].reset_index(drop=True)[-window:])\n",
    "   \n",
    "    return mean_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:15.391759Z",
     "start_time": "2018-04-03T15:10:15.247076Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate_lgb(X_train, y_train, X_valid, y_valid):\n",
    "    \n",
    "    \n",
    "    d1 = lgb.Dataset(X_train, y_train, weight=np.linspace(0.5, 1, X_train.shape[0]))\n",
    "    d2 = lgb.Dataset(X_valid, y_valid)\n",
    "    \n",
    "    params = {\n",
    "        'objective':'regression',    \n",
    "        'metric': 'l1', \n",
    "        'learning_rate': 0.160042,\n",
    "        'random_state':42\n",
    "    }\n",
    "    \n",
    "    gbm = lgb.train(params, d1, verbose_eval=None, valid_sets=d2, \n",
    "                    num_boost_round=50000, early_stopping_rounds=100)\n",
    "    \n",
    "    y_hat = gbm.predict(X_valid)\n",
    "    opt_boost_rounds = gbm.best_iteration\n",
    "    \n",
    "    return y_hat, opt_boost_rounds \n",
    "\n",
    "\n",
    "\n",
    "def train_lgb(X_train, y_train, X_test, opt_boost_rounds):\n",
    "    \n",
    "    d1 = lgb.Dataset(X_train, y_train, weight=np.linspace(0.5, 1, X_train.shape[0]))\n",
    "    \n",
    "    params = {\n",
    "        'objective':'regression',    \n",
    "        'metric': 'l1', \n",
    "        'learning_rate': 0.160042,\n",
    "        'random_state':42\n",
    "    }\n",
    "    \n",
    "    gbm = lgb.train(params, d1, verbose_eval=None, num_boost_round=opt_boost_rounds)\n",
    "    \n",
    "    y_hat = gbm.predict(X_test)\n",
    "\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:16.214908Z",
     "start_time": "2018-04-03T15:10:16.191300Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_rf(X_train, y_train, X_valid):\n",
    "\n",
    "    rf = RandomForestRegressor(max_features='sqrt', n_estimators=142, n_jobs=-1, random_state=4224)\n",
    "    rf.fit(X_train, y_train, sample_weight=np.linspace(0.5, 1, X_train.shape[0]) )\n",
    "    y_hat = rf.predict(X_valid)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:16.812914Z",
     "start_time": "2018-04-03T15:10:16.802762Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_score(pred, fact, index_mult):\n",
    "    return mean_absolute_error(pred,fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:17.211822Z",
     "start_time": "2018-04-03T15:10:17.196780Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_y_hats(y_hats):\n",
    "    X_stack = pd.DataFrame({})\n",
    "    for i in range(0, len(y_hats)):\n",
    "        X_stack['stack'+str(i)] = y_hats[i]\n",
    "    return X_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:17.510135Z",
     "start_time": "2018-04-03T15:10:17.498084Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_stack(X_stack, y, model):\n",
    "    model.fit(X_stack, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:17.791921Z",
     "start_time": "2018-04-03T15:10:17.767262Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_harmonic_features(x, col, period=24):\n",
    "    x['sin_'+col] = np.sin(x[col] * 2 * np.pi / period)\n",
    "    x['cos_'+col] = np.cos(x[col] * 2 * np.pi / period)\n",
    "    x = x.drop(col, axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:18.695945Z",
     "start_time": "2018-04-03T15:10:18.683663Z"
    }
   },
   "outputs": [],
   "source": [
    "train['minutes_in_day'] = train['hour']*60 + train['minute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:20.579427Z",
     "start_time": "2018-04-03T15:10:20.570290Z"
    }
   },
   "outputs": [],
   "source": [
    "train['holidays'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:21.084872Z",
     "start_time": "2018-04-03T15:10:21.038226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>Value</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week_day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>minutes_in_day</th>\n",
       "      <th>holidays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>91600</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>136500</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>335400</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>379000</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>344100</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp  ForecastId   Value  year  month  day  week_day  hour  minute  \\\n",
       "0 2015-01-01           0   91600  2015      1    1         3     0       0   \n",
       "1 2015-01-02           0  136500  2015      1    2         4     0       0   \n",
       "2 2015-01-03           0  335400  2015      1    3         5     0       0   \n",
       "3 2015-01-04           0  379000  2015      1    4         6     0       0   \n",
       "4 2015-01-05           0  344100  2015      1    5         0     0       0   \n",
       "\n",
       "   minutes_in_day  holidays  \n",
       "0               0         0  \n",
       "1               0         0  \n",
       "2               0         0  \n",
       "3               0         0  \n",
       "4               0         0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def lin_reg(x):\n",
    "    return np.sum( (X_valid_v['Value'] - np.dot(X_valid_stack,x) )**2 ) \n",
    "\n",
    "\n",
    "def constr_sum(x):\n",
    "    return np.sum(x)-1\n",
    "\n",
    "result = minimize(lin_reg, [0,0,0,0], method='SLSQP',\n",
    "                   bounds=((0.0,1.0), (0.0,1.0), (0.0,1.0), (0.0,1.0)), \n",
    "                   constraints=({'type': 'eq', 'fun': lambda x: np.sum(x)-1}), \n",
    "                   tol=None, callback=None, options={'maxiter':100, 'disp':True})\n",
    "x = result['x']\n",
    "y_lr_minimize = np.sum(X_valid_stack*x, axis=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, fmin_slsqp\n",
    "\n",
    "def lin_reg(x):\n",
    "    # featurex - matrix of X \n",
    "    # x == b in linear regression \n",
    "    return np.sum( (y_true - np.dot(features,x) )**2 ) \n",
    "\n",
    "def constr_sum(x):\n",
    "    return np.sum(x)-1\n",
    "\n",
    "x0 = [0,0,0,0]\n",
    "\n",
    "result = minimize(lin_reg, x0 , method='SLSQP',\n",
    "                   bounds=((0.0,1.0), (0.0,1.0), (0.0,1.0), (0.0,1.0)), \n",
    "                   constraints=({'type': 'eq', 'fun': lambda x: np.sum(x)-1}), \n",
    "                   tol=None, callback=None, options={'maxiter':100, 'disp':True})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:25.370000Z",
     "start_time": "2018-04-03T15:10:25.297469Z"
    }
   },
   "outputs": [],
   "source": [
    "def nan_fill(X):\n",
    "    \n",
    "    values_dict = dict(X[['Timestamp', 'Value']].values)\n",
    "    \n",
    "    for i in np.where(X['Value'].isnull())[0]:\n",
    "        val = []\n",
    "        for j in [-365, -14, -7, 7, 14, 365]:\n",
    "            ind = X['Timestamp']==(X['Timestamp'][i]+timedelta(days=j))\n",
    "            value = list(X['Value'][ind])\n",
    "            if (value!=[]):\n",
    "                val.append(value[0])\n",
    "        \n",
    "        X['Value'][i] = np.median(val)\n",
    "        # X['Value'] = X['Value'].interpolate()\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:26.199966Z",
     "start_time": "2018-04-03T15:10:26.058438Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "\n",
    "def validate_stack(X_stack, y, model):\n",
    "    y_cros_val_pred = cross_val_predict(model, X_stack, y=y, cv=5, n_jobs=-1)\n",
    "    return y_cros_val_pred\n",
    "\n",
    "def cv_lr(X_stack, y, model):\n",
    "    \n",
    "    # cros val lasso on X_stack \n",
    "    \n",
    "    y_cros_val_pred = pd.DataFrame({})\n",
    "    coefs = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_stack):\n",
    "        X_train, X_test = X_stack.iloc[train_index], X_stack.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model_temp = model \n",
    "        model_temp.fit(X_train,y_train)\n",
    "        y_hat = model_temp.predict(X_test)\n",
    "        coefs.append(model_temp.coef_)\n",
    "        \n",
    "        temp_df = pd.DataFrame({'id': test_index, 'Value': y_hat})\n",
    "        y_cros_val_pred = pd.concat([y_cros_val_pred, temp_df], axis=0)\n",
    "      \n",
    "    y_cros_val_pred = y_cros_val_pred.sort_values(by='id')\n",
    "    \n",
    "    #divide by sum - due to overfit of model, with dividing - coefs ~ weights of models\n",
    "    return list(y_cros_val_pred['Value']) / np.sum(np.mean(coefs,axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:10:26.759449Z",
     "start_time": "2018-04-03T15:10:26.711487Z"
    }
   },
   "outputs": [],
   "source": [
    "def w_avg(x):       \n",
    "    \n",
    "    if (len(x)==1):\n",
    "        a = x\n",
    "    \n",
    "    if (len(x)==2):\n",
    "        a = (np.array([0.25, 0.75])*x).mean()\n",
    "        \n",
    "    if (len(x)==3):\n",
    "        a = (np.array([0.15, 0.25, 0.6])*x).mean()\n",
    "        \n",
    "    if (len(x)==4):\n",
    "        a = (np.array([0.1, 0.2, 0.3, 0.4])*x).mean()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:15:20.283288Z",
     "start_time": "2018-04-03T15:10:59.553420Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Best model is rf_log  na value: 0 0\n",
      "loss: 0.29044351296387816\n",
      "{'mean_all': 115873.92857142857, 'mean_3': 115873.92857142857, 'median_all': 114157.14285714286, 'median_3': 114157.14285714286, 'rf': 104140.33879066099, 'rf_mean': 118974.76113168437, 'rf_log': 102500.42108731047, 'rf_mean_log': 119055.63560765308, 'lr_stack': 105747.11416269254}\n",
      "-------------------------------\n",
      "2 Best model is rf_log  na value: 0 0\n",
      "loss: -2.231490123871463\n",
      "{'mean_all': 31451.836734693883, 'mean_3': 31451.836734693883, 'median_all': 25414.285714285714, 'median_3': 25414.285714285714, 'rf': 30328.381468946933, 'rf_mean': 36197.11129791062, 'rf_log': 22297.631092112075, 'rf_mean_log': 28371.50191721633, 'lr_stack': 33503.0749836989}\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eamag/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Best model is median_all  na value: 0 0\n",
      "loss: -0.26324467418740016\n",
      "{'mean_all': 114616.17346938775, 'mean_3': 114616.17346938775, 'median_all': 95085.71428571429, 'median_3': 95085.71428571429, 'rf': 100613.41156908429, 'rf_mean': 97372.97354482677, 'rf_log': 120946.98060961254, 'rf_mean_log': 104835.45919844457, 'lr_stack': 104786.06084893235}\n",
      "-------------------------------\n",
      "4 Best model is rf_log  na value: 0 0\n",
      "loss: 0.42097832726297413\n",
      "{'mean_all': 217057.9591836735, 'mean_3': 217057.9591836735, 'median_all': 192458.57142857142, 'median_3': 192458.57142857142, 'rf': 236961.2869808353, 'rf_mean': 313453.19043807214, 'rf_log': 151512.56476671985, 'rf_mean_log': 299193.55407696596, 'lr_stack': 160083.7869802524}\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eamag/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Best model is rf_mean_log  na value: 0 0\n",
      "loss: 0.6132215037519412\n",
      "{'mean_all': 205262.65306122447, 'mean_3': 205262.65306122447, 'median_all': 171951.42857142858, 'median_3': 171951.42857142858, 'rf': 187847.88211595733, 'rf_mean': 182663.58939641507, 'rf_log': 162077.298518407, 'rf_mean_log': 158589.5439786893, 'lr_stack': 181632.6454254011}\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eamag/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Best model is median_all  na value: 0 0\n",
      "loss: -0.21379413551855708\n",
      "{'mean_all': 176756.83673469388, 'mean_3': 176756.83673469388, 'median_all': 164515.7142857143, 'median_3': 164515.7142857143, 'rf': 171302.82521931716, 'rf_mean': 173367.25470524226, 'rf_log': 193819.52110313106, 'rf_mean_log': 176136.2977121872, 'lr_stack': 169588.03166557397}\n",
      "-------------------------------\n",
      "7 Best model is rf_log  na value: 0 0\n",
      "loss: 0.04903877093704079\n",
      "{'mean_all': 60950.20408163265, 'mean_3': 60950.20408163265, 'median_all': 58351.42857142857, 'median_3': 58351.42857142857, 'rf': 66264.21193107194, 'rf_mean': 81516.3102619677, 'rf_log': 52989.577492620774, 'rf_mean_log': 77837.20730917063, 'lr_stack': 66864.9622601671}\n",
      "-------------------------------\n",
      "8 Best model is median_all  na value: 0 0\n",
      "loss: -3.242767367536893\n",
      "{'mean_all': 27717.448979591838, 'mean_3': 27717.448979591838, 'median_all': 19952.85714285714, 'median_3': 19952.85714285714, 'rf': 24477.088053772593, 'rf_mean': 24779.31002647078, 'rf_log': 21406.045101416683, 'rf_mean_log': 22664.71663694664, 'lr_stack': 21692.113826756144}\n",
      "-------------------------------\n",
      "9 Best model is median_all  na value: 0 0\n",
      "loss: -1.4780107283559234\n",
      "{'mean_all': 85950.35714285714, 'mean_3': 85950.35714285714, 'median_all': 83832.85714285714, 'median_3': 83832.85714285714, 'rf': 93967.02944640255, 'rf_mean': 102912.0560878441, 'rf_log': 88878.01092455447, 'rf_mean_log': 101679.70310291665, 'lr_stack': 102062.62681723753}\n",
      "-------------------------------\n",
      "10 Best model is rf  na value: 0 0\n",
      "loss: -19.120541122264967\n",
      "{'mean_all': 265919.64285714284, 'mean_3': 265919.64285714284, 'median_all': 284928.5714285714, 'median_3': 284928.5714285714, 'rf': 223839.253300681, 'rf_mean': 264104.3205657913, 'rf_log': 283630.1202100573, 'rf_mean_log': 284925.76403484144, 'lr_stack': 269226.85753413255}\n",
      "-------------------------------\n",
      "11 Best model is median_all  na value: 0 0\n",
      "loss: -2.220048429948896\n",
      "{'mean_all': 40727.80612244898, 'mean_3': 40727.80612244898, 'median_all': 35465.71428571428, 'median_3': 35465.71428571428, 'rf': 41788.5997485332, 'rf_mean': 51340.21249328102, 'rf_log': 46711.23765582795, 'rf_mean_log': 73966.33177871181, 'lr_stack': 44931.443667600404}\n",
      "-------------------------------\n",
      "14 Best model is rf_log  na value: 0 0\n",
      "loss: -0.22902226716351315\n",
      "{'mean_all': 106109.74489795919, 'mean_3': 106109.74489795919, 'median_all': 77741.42857142857, 'median_3': 77741.42857142857, 'rf': 98988.34534285942, 'rf_mean': 87774.83323440807, 'rf_log': 76486.96144986498, 'rf_mean_log': 78148.29038134504, 'lr_stack': 90396.15896534217}\n",
      "-------------------------------\n",
      "17 Best model is mean_all  na value: 0 0\n",
      "loss: -3.8279075871999417\n",
      "{'mean_all': 336278.4183673469, 'mean_3': 336278.4183673469, 'median_all': 361381.4285714286, 'median_3': 361381.4285714286, 'rf': 338156.063700745, 'rf_mean': 408918.38983556913, 'rf_log': 337629.464641603, 'rf_mean_log': 403289.117018248, 'lr_stack': 355233.7704935646}\n",
      "-------------------------------\n",
      "18 Best model is rf_log  na value: 0 0\n",
      "loss: -0.3437743731011671\n",
      "{'mean_all': 108625.10204081633, 'mean_3': 108625.10204081633, 'median_all': 118638.57142857143, 'median_3': 118638.57142857143, 'rf': 105610.75379871334, 'rf_mean': 135876.45794770075, 'rf_log': 97903.1335768881, 'rf_mean_log': 127076.71413107567, 'lr_stack': 109932.59882165442}\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eamag/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Best model is rf_log  na value: 0 0\n",
      "loss: -1.244444725392285\n",
      "{'mean_all': 394509.693877551, 'mean_3': 394509.693877551, 'median_all': 385357.14285714284, 'median_3': 385357.14285714284, 'rf': 388428.0949528958, 'rf_mean': 414683.8638456593, 'rf_log': 374778.85268570395, 'rf_mean_log': 399803.62981204607, 'lr_stack': 429192.0456947452}\n",
      "-------------------------------\n",
      "21 Best model is mean_all  na value: 0 0\n",
      "loss: -5.193973179590376\n",
      "{'mean_all': 364050.45918367343, 'mean_3': 364050.45918367343, 'median_all': 381188.5714285714, 'median_3': 381188.5714285714, 'rf': 403048.058296741, 'rf_mean': 413476.91558450036, 'rf_log': 451977.1509793405, 'rf_mean_log': 423931.96562588634, 'lr_stack': 381653.88430796965}\n",
      "-------------------------------\n",
      "22 Best model is mean_all  na value: 0 0\n",
      "loss: -16.46101083216286\n",
      "{'mean_all': 301804.7959183674, 'mean_3': 301804.7959183674, 'median_all': 336182.85714285716, 'median_3': 336182.85714285716, 'rf': 433813.15781480115, 'rf_mean': 489370.8601653198, 'rf_log': 534299.0981645795, 'rf_mean_log': 653318.351256144, 'lr_stack': 393342.1622162122}\n",
      "-------------------------------\n",
      "23 Best model is rf_mean  na value: 0 0\n",
      "loss: -16.840775483842325\n",
      "{'mean_all': 50567.24489795918, 'mean_3': 50567.24489795918, 'median_all': 49611.42857142857, 'median_3': 49611.42857142857, 'rf': 53035.19477155786, 'rf_mean': 49086.12020162618, 'rf_log': 49887.13800732034, 'rf_mean_log': 49647.33908171285, 'lr_stack': 54978.444761758285}\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eamag/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Best model is mean_all  na value: 0 0\n",
      "loss: -1.5824527856972503\n",
      "{'mean_all': 102849.0306122449, 'mean_3': 102849.0306122449, 'median_all': 106188.57142857143, 'median_3': 106188.57142857143, 'rf': 117723.31431769939, 'rf_mean': 116499.7675263399, 'rf_log': 118872.47396250493, 'rf_mean_log': 117568.7178039144, 'lr_stack': 115310.2965019326}\n",
      "-------------------------------\n",
      "25 Best model is median_all  na value: 0 0\n",
      "loss: 0.1089233787923164\n",
      "{'mean_all': 108193.52040816325, 'mean_3': 108193.52040816325, 'median_all': 95488.57142857143, 'median_3': 95488.57142857143, 'rf': 95981.73817317755, 'rf_mean': 138358.46214645635, 'rf_log': 104220.38399074503, 'rf_mean_log': 126648.25113140914, 'lr_stack': 104246.19310839628}\n",
      "-------------------------------\n",
      "26 Best model is rf_mean  na value: 0 0\n",
      "loss: -1.2465978684018122\n",
      "{'mean_all': 134933.67346938775, 'mean_3': 134933.67346938775, 'median_all': 134490.0, 'median_3': 134490.0, 'rf': 132626.9284430431, 'rf_mean': 127377.72594761559, 'rf_log': 135282.25034284053, 'rf_mean_log': 130006.76719033577, 'lr_stack': 147692.90279799287}\n",
      "-------------------------------\n",
      "27 Best model is mean_all  na value: 0 0\n",
      "loss: -1.1469286769192815\n",
      "{'mean_all': 80270.1530612245, 'mean_3': 80270.1530612245, 'median_all': 84004.28571428571, 'median_3': 84004.28571428571, 'rf': 98502.46674516641, 'rf_mean': 109165.04916154858, 'rf_log': 206623.2689586491, 'rf_mean_log': 161088.06222133213, 'lr_stack': 82387.16584542743}\n",
      "-------------------------------\n",
      "28 Best model is mean_all  na value: 0 0\n",
      "loss: -0.14247142687913095\n",
      "{'mean_all': 93792.39795918367, 'mean_3': 93792.39795918367, 'median_all': 95734.28571428571, 'median_3': 95734.28571428571, 'rf': 106675.29873821976, 'rf_mean': 115381.40548788685, 'rf_log': 97925.86957944489, 'rf_mean_log': 114723.81730060723, 'lr_stack': 103317.60233642579}\n",
      "-------------------------------\n",
      "29 Best model is rf_log  na value: 0 0\n",
      "loss: 0.11156920493548772\n",
      "{'mean_all': 59981.83673469388, 'mean_3': 59981.83673469388, 'median_all': 54338.57142857143, 'median_3': 54338.57142857143, 'rf': 54234.126597238486, 'rf_mean': 55472.808277280616, 'rf_log': 50612.22014658458, 'rf_mean_log': 52673.07485498522, 'lr_stack': 55254.360942421576}\n",
      "-------------------------------\n",
      "30 Best model is mean_all  na value: 0 0\n",
      "loss: -0.5207901446764676\n",
      "{'mean_all': 117655.10204081633, 'mean_3': 117655.10204081633, 'median_all': 117687.14285714286, 'median_3': 117687.14285714286, 'rf': 135573.12808478423, 'rf_mean': 137214.16275792682, 'rf_log': 124800.2223940932, 'rf_mean_log': 131729.3389822401, 'lr_stack': 130964.06280667576}\n",
      "-------------------------------\n",
      "31 Best model is rf_mean_log  na value: 0 0\n",
      "loss: -1.0194969143648307\n",
      "{'mean_all': 257173.112244898, 'mean_3': 257173.112244898, 'median_all': 279188.5714285714, 'median_3': 279188.5714285714, 'rf': 331865.132865359, 'rf_mean': 242602.12675706734, 'rf_log': 288315.10798552976, 'rf_mean_log': 227517.4572477439, 'lr_stack': 272497.95022112527}\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eamag/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Best model is mean_all  na value: 0 0\n",
      "loss: 0.8039085074601877\n",
      "{'mean_all': 32538.26530612245, 'mean_3': 32538.26530612245, 'median_all': 32622.85714285714, 'median_3': 32622.85714285714, 'rf': 35596.73956014582, 'rf_mean': 32721.56743423171, 'rf_log': 45428.70757098086, 'rf_mean_log': 42111.89833919929, 'lr_stack': 39436.45262161209}\n",
      "-------------------------------\n",
      "33 Best model is rf_mean_log  na value: 0 0\n",
      "loss: -4.425530025940663e+32\n",
      "{'mean_all': 60170.40816326531, 'mean_3': 60170.40816326531, 'median_all': 35890.0, 'median_3': 35890.0, 'rf': 41779.28481165756, 'rf_mean': 29437.588403893547, 'rf_log': 27765.29970114125, 'rf_mean_log': 26827.12404777771, 'lr_stack': 46394.62314271897}\n",
      "-------------------------------\n",
      "34 Best model is median_all  na value: 0 0\n",
      "loss: -8.788113876827106\n",
      "{'mean_all': 15323.877551020409, 'mean_3': 15323.877551020409, 'median_all': 15184.285714285714, 'median_3': 15184.285714285714, 'rf': 17102.443445851106, 'rf_mean': 15849.858241006752, 'rf_log': 16026.318471262428, 'rf_mean_log': 16698.243962709847, 'lr_stack': 16319.757466751933}\n",
      "-------------------------------\n",
      "35 Best model is median_all  na value: 0 0\n",
      "loss: 0.37841317096130467\n",
      "{'mean_all': 127323.87755102041, 'mean_3': 127323.87755102041, 'median_all': 120864.28571428571, 'median_3': 120864.28571428571, 'rf': 150193.9486846202, 'rf_mean': 191791.49497150842, 'rf_log': 127504.43962079656, 'rf_mean_log': 208706.5330438933, 'lr_stack': 136162.34231154155}\n",
      "-------------------------------\n",
      "36 Best model is median_all  na value: 0 0\n",
      "loss: -1.8624464578351683\n",
      "{'mean_all': 97420.61224489796, 'mean_3': 97420.61224489796, 'median_all': 97154.28571428571, 'median_3': 97154.28571428571, 'rf': 100500.98433054896, 'rf_mean': 104505.93865785397, 'rf_log': 100800.10366815633, 'rf_mean_log': 104983.73774139905, 'lr_stack': 97710.09373398987}\n",
      "-------------------------------\n",
      "38 Best model is median_all  na value: 0 0\n",
      "loss: -3.386725222732575\n",
      "{'mean_all': 226925.91836734695, 'mean_3': 226925.91836734695, 'median_all': 209221.42857142858, 'median_3': 209221.42857142858, 'rf': 250720.05015064275, 'rf_mean': 239290.8988216232, 'rf_log': 255742.28627735467, 'rf_mean_log': 245585.17249806135, 'lr_stack': 224026.69489355697}\n",
      "-------------------------------\n",
      "40 Best model is rf_mean_log  na value: 0 0\n",
      "loss: 0.17346031702117692\n",
      "{'mean_all': 15220.714285714286, 'mean_3': 15220.714285714286, 'median_all': 13865.714285714286, 'median_3': 13865.714285714286, 'rf': 20308.214963136, 'rf_mean': 15827.64141984097, 'rf_log': 16910.864171023797, 'rf_mean_log': 13151.510488634745, 'lr_stack': 15667.583482759359}\n",
      "-------------------------------\n",
      "41 Best model is median_all  na value: 0 0\n",
      "loss: -4.63090612976822\n",
      "{'mean_all': 153897.0408163265, 'mean_3': 153897.0408163265, 'median_all': 145748.57142857142, 'median_3': 145748.57142857142, 'rf': 172528.14380970874, 'rf_mean': 181891.6338846027, 'rf_log': 164756.3150030994, 'rf_mean_log': 179937.1424033333, 'lr_stack': 164714.8936951833}\n",
      "-------------------------------\n",
      "43 Best model is rf_log  na value: 0 0\n",
      "loss: -0.9786542985648989\n",
      "{'mean_all': 32685.051020408162, 'mean_3': 32685.051020408162, 'median_all': 33631.42857142857, 'median_3': 33631.42857142857, 'rf': 35179.14393271253, 'rf_mean': 33279.20612973386, 'rf_log': 28912.28474055404, 'rf_mean_log': 31055.202770247655, 'lr_stack': 34647.209199132005}\n",
      "-------------------------------\n",
      "44 Best model is mean_all  na value: 0 0\n",
      "loss: -0.6951421066169494\n",
      "{'mean_all': 18035.051020408162, 'mean_3': 18035.051020408162, 'median_all': 18075.714285714286, 'median_3': 18075.714285714286, 'rf': 19127.40582971502, 'rf_mean': 22065.696567914365, 'rf_log': 20129.743226602346, 'rf_mean_log': 21517.50757585623, 'lr_stack': 20462.047088899053}\n",
      "-------------------------------\n",
      "45 Best model is rf_log  na value: 0 0\n",
      "loss: -0.37011738046763965\n",
      "{'mean_all': 41997.09183673469, 'mean_3': 41997.09183673469, 'median_all': 42510.0, 'median_3': 42510.0, 'rf': 46387.3004326818, 'rf_mean': 52100.51273123005, 'rf_log': 34257.762533951296, 'rf_mean_log': 43103.013881541, 'lr_stack': 41383.459673231795}\n",
      "-------------------------------\n",
      "47 Best model is median_all  na value: 0 0\n",
      "loss: -14.778146478734977\n",
      "{'mean_all': 17362.397959183672, 'mean_3': 17362.397959183672, 'median_all': 17348.571428571428, 'median_3': 17348.571428571428, 'rf': 17775.882055998696, 'rf_mean': 19277.169471461017, 'rf_log': 19180.768239594046, 'rf_mean_log': 19362.412225526754, 'lr_stack': 17433.036757411337}\n",
      "-------------------------------\n",
      "48 Best model is median_all  na value: 0 0\n",
      "loss: 0.4740463461584046\n",
      "{'mean_all': 169554.74489795917, 'mean_3': 169554.74489795917, 'median_all': 168948.57142857142, 'median_3': 168948.57142857142, 'rf': 189559.10380583841, 'rf_mean': 312925.1076003141, 'rf_log': 231011.8082213385, 'rf_mean_log': 346522.3286485298, 'lr_stack': 191034.5548949705}\n",
      "-------------------------------\n",
      "49 Best model is median_all  na value: 0 0\n",
      "loss: -0.8119824300566938\n",
      "{'mean_all': 21220.051020408162, 'mean_3': 21220.051020408162, 'median_all': 17782.85714285714, 'median_3': 17782.85714285714, 'rf': 25474.25153596421, 'rf_mean': 26089.44762459981, 'rf_log': 20799.139709916904, 'rf_mean_log': 21256.712992327124, 'lr_stack': 20552.189738977955}\n",
      "-------------------------------\n",
      "50 Best model is rf  na value: 0 0\n",
      "loss: 0.5606438536118608\n",
      "{'mean_all': 59901.1224489796, 'mean_3': 59901.1224489796, 'median_all': 69327.14285714286, 'median_3': 69327.14285714286, 'rf': 48163.17831641741, 'rf_mean': 88745.02191822861, 'rf_log': 66492.22386107921, 'rf_mean_log': 95873.54142207978, 'lr_stack': 62286.609476399724}\n",
      "-------------------------------\n",
      "51 Best model is rf_log  na value: 0 0\n",
      "loss: 0.7068695898314459\n",
      "{'mean_all': 132472.44897959183, 'mean_3': 132472.44897959183, 'median_all': 150287.14285714287, 'median_3': 150287.14285714287, 'rf': 162562.2563546507, 'rf_mean': 236193.8473960273, 'rf_log': 91870.09605794233, 'rf_mean_log': 191531.85916569378, 'lr_stack': 100178.0643821506}\n",
      "-------------------------------\n",
      "52 Best model is mean_all  na value: 0 0\n",
      "loss: -1.0346241774007456\n",
      "{'mean_all': 38438.010204081635, 'mean_3': 38438.010204081635, 'median_all': 39911.42857142857, 'median_3': 39911.42857142857, 'rf': 58316.53564385949, 'rf_mean': 54177.77845806563, 'rf_log': 76662.05521455727, 'rf_mean_log': 67291.20538555099, 'lr_stack': 41453.27368989033}\n",
      "-------------------------------\n",
      "53 Best model is median_all  na value: 0 0\n",
      "loss: -0.8959797899922437\n",
      "{'mean_all': 57804.0306122449, 'mean_3': 57804.0306122449, 'median_all': 40574.28571428572, 'median_3': 40574.28571428572, 'rf': 71264.49048457785, 'rf_mean': 58766.37907935887, 'rf_log': 51168.70838369798, 'rf_mean_log': 51551.78069233793, 'lr_stack': 46092.20129837182}\n",
      "-------------------------------\n",
      "54 Best model is mean_all  na value: 0 0\n",
      "loss: -0.15278202928349938\n",
      "{'mean_all': 258518.6224489796, 'mean_3': 258518.6224489796, 'median_all': 270015.71428571426, 'median_3': 270015.71428571426, 'rf': 313056.43732955214, 'rf_mean': 325859.933340565, 'rf_log': 285577.9474950198, 'rf_mean_log': 314864.6893989887, 'lr_stack': 320268.9854792709}\n",
      "-------------------------------\n",
      "55 Best model is median_all  na value: 0 0\n",
      "loss: 0.036667561554789785\n",
      "{'mean_all': 59583.57142857143, 'mean_3': 59583.57142857143, 'median_all': 47554.28571428572, 'median_3': 47554.28571428572, 'rf': 90331.02876392746, 'rf_mean': 96018.2443305329, 'rf_log': 74768.61582326611, 'rf_mean_log': 85925.17602956606, 'lr_stack': 56040.36780090397}\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eamag/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 Best model is median_all  na value: 0 0\n",
      "loss: -1.1426745443549637\n",
      "{'mean_all': 250397.193877551, 'mean_3': 250397.193877551, 'median_all': 216272.85714285713, 'median_3': 216272.85714285713, 'rf': 286200.6319544509, 'rf_mean': 243611.89640740285, 'rf_log': 228957.02887511402, 'rf_mean_log': 228520.47087818378, 'lr_stack': 261596.4203311668}\n",
      "-------------------------------\n",
      "57 Best model is rf_log  na value: 0 0\n",
      "loss: -0.4790873801262545\n",
      "{'mean_all': 275087.85714285716, 'mean_3': 275087.85714285716, 'median_all': 272811.4285714286, 'median_3': 272811.4285714286, 'rf': 294480.3804220108, 'rf_mean': 339597.639000325, 'rf_log': 247792.3563914217, 'rf_mean_log': 342818.700579018, 'lr_stack': 296288.60417742113}\n",
      "-------------------------------\n",
      "58 Best model is mean_all  na value: 0 0\n",
      "loss: -1.7285938158745373\n",
      "{'mean_all': 63341.58163265306, 'mean_3': 63341.58163265306, 'median_all': 72625.71428571429, 'median_3': 72625.71428571429, 'rf': 79777.64338802014, 'rf_mean': 85418.10023662285, 'rf_log': 102084.51407519427, 'rf_mean_log': 100863.39946827185, 'lr_stack': 73671.25124731244}\n",
      "-------------------------------\n",
      "60 Best model is rf_mean_log  na value: 0 0\n",
      "loss: -0.13220498895107546\n",
      "{'mean_all': 164944.79591836734, 'mean_3': 164944.79591836734, 'median_all': 175248.57142857142, 'median_3': 175248.57142857142, 'rf': 179527.59572800767, 'rf_mean': 135950.1301747474, 'rf_log': 94156.88449401462, 'rf_mean_log': 78157.91980656765, 'lr_stack': 99743.66831423654}\n",
      "-------------------------------\n",
      "61 Best model is mean_all  na value: 0 0\n",
      "loss: 0.569417457907138\n",
      "{'mean_all': 54543.82653061225, 'mean_3': 54543.82653061225, 'median_all': 61672.857142857145, 'median_3': 61672.857142857145, 'rf': 62408.47454533823, 'rf_mean': 85048.2608191494, 'rf_log': 65852.04419962474, 'rf_mean_log': 81090.86014537555, 'lr_stack': 67582.0320892428}\n",
      "-------------------------------\n",
      "63 Best model is mean_all  na value: 0 0\n",
      "loss: -2.7394935136964484\n",
      "{'mean_all': 102646.02040816327, 'mean_3': 102646.02040816327, 'median_all': 105325.71428571429, 'median_3': 105325.71428571429, 'rf': 157187.50155042822, 'rf_mean': 176359.89303385673, 'rf_log': 185309.24611095706, 'rf_mean_log': 261001.3953633343, 'lr_stack': 125030.65356023911}\n",
      "-------------------------------\n",
      "64 Best model is rf_log  na value: 0 0\n",
      "loss: -0.9231082315576502\n",
      "{'mean_all': 53719.69387755102, 'mean_3': 53719.69387755102, 'median_all': 43501.42857142857, 'median_3': 43501.42857142857, 'rf': 59482.3155105745, 'rf_mean': 53552.193480246955, 'rf_log': 42677.573790845236, 'rf_mean_log': 43467.85489116444, 'lr_stack': 45260.07865029792}\n",
      "-------------------------------\n",
      "65 Best model is mean_all  na value: 0 0\n",
      "loss: -3.133919210486172\n",
      "{'mean_all': 98048.7755102041, 'mean_3': 98048.7755102041, 'median_all': 98381.42857142857, 'median_3': 98381.42857142857, 'rf': 123451.55430239785, 'rf_mean': 177036.87922268227, 'rf_log': 183951.75558864092, 'rf_mean_log': 240871.08131037414, 'lr_stack': 106504.15011178383}\n",
      "-------------------------------\n",
      "66 Best model is median_all  na value: 0 0\n",
      "loss: -0.6370186648929319\n",
      "{'mean_all': 74882.6530612245, 'mean_3': 74882.6530612245, 'median_all': 74848.57142857143, 'median_3': 74848.57142857143, 'rf': 109628.00065335298, 'rf_mean': 110983.96349315872, 'rf_log': 105921.93626349981, 'rf_mean_log': 98603.3139953915, 'lr_stack': 86845.02633680147}\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0b890be4c088>\u001b[0m in \u001b[0;36mtrain_rf\u001b[0;34m(X_train, y_train, X_valid)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m142\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/general/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "losses = []\n",
    "iids = []\n",
    "\n",
    "sub = pd.DataFrame({})\n",
    "cat_cols = ['week_day','hour','minute','month', 'holidays']\n",
    "\n",
    "for i in pd.unique(train['ForecastId']):\n",
    " \n",
    "    rf_stack = RandomForestRegressor(n_estimators=1000, random_state=42, n_jobs=-1)\n",
    "    lr_stack = Lasso(alpha=1, fit_intercept=False, max_iter=3000, tol=0.0001, positive=True, random_state=424142)\n",
    "\n",
    "    # prepare train and test Dfs \n",
    "    days_in_train = 90\n",
    "    X_train = train[train['ForecastId']==i].reset_index(drop=True)[-days_in_train:].reset_index(drop=True)\n",
    "    \n",
    "    # train on last 1.5 year \n",
    "    na_values_before = np.sum(X_train['Value'].isnull())\n",
    "    X_train = nan_fill(X_train)\n",
    "    na_values_after = np.sum(X_train['Value'].isnull())\n",
    "    X_train = X_train.dropna(subset=['Value']).reset_index(drop=True)\n",
    "    \n",
    "    X_train['Value_log'] = np.log1p(X_train['Value'])\n",
    "    \n",
    "    # drop outliers in train data set \n",
    "    #up_border = X_train['Value'].quantile(0.985)\n",
    "    #low_border = X_train['Value'].quantile(0.015)\n",
    "    #X_train = X_train[(X_train['Value']<=up_border) & (X_train['Value']>=low_border)].reset_index(drop=True)\n",
    "    \n",
    "    # prepare 'train_v' and 'valid_v' data frames - for validation \n",
    "    X_test = X_train \n",
    "    \n",
    "    obs_in_test = 35\n",
    "    X_train_v = X_train[:-obs_in_test].reset_index(drop=True)\n",
    "    X_valid_v = X_train[-obs_in_test:].reset_index(drop=True)\n",
    "    \n",
    "    # prepare features \n",
    "        # for train\n",
    "    X_train_ohe, X_test_ohe = feature_preprocessing(X_train, X_test, cat_cols, cat_type='ohe')\n",
    "    X_train_meanenc, X_test_meanenc = feature_preprocessing(X_train, X_test, cat_cols, cat_type='mean_enc')\n",
    "    \n",
    "        # for validation \n",
    "    X_train_v_ohe, X_valid_v_ohe = feature_preprocessing(X_train_v, X_valid_v, cat_cols, cat_type='ohe')\n",
    "    X_train_v_meanenc, X_valid_v_meanenc = feature_preprocessing(X_train_v, X_valid_v, cat_cols, cat_type='mean_enc')\n",
    "    \n",
    "        # group by mean\n",
    "    y_hat_grby_mean = train_groupby(X_train_v, X_valid_v, window=999999, how='mean')\n",
    "    y_hat_grby3_mean = train_groupby(X_train_v, X_valid_v, window=obs_in_test*3, how='mean')\n",
    "    \n",
    "        # group by median\n",
    "    y_hat_grby_median = train_groupby(X_train_v, X_valid_v, window=999999, how='median')\n",
    "    y_hat_grby3_median = train_groupby(X_train_v, X_valid_v, window=obs_in_test*3, how='median')\n",
    "    \n",
    "        # RandomForest \n",
    "    y_rf = train_rf(X_train_v_ohe, X_train_v['Value'], X_valid_v_ohe)\n",
    "    y_rf_mean = train_rf(X_train_v_meanenc, X_train_v['Value'], X_valid_v_meanenc)\n",
    "    y_rf_log = np.exp(train_rf(X_train_v_ohe, X_train_v['Value_log'], X_valid_v_ohe)) - 1\n",
    "    y_rf_mean_log = np.exp(train_rf(X_train_v_meanenc, X_train_v['Value_log'], X_valid_v_meanenc)) - 1\n",
    "    \n",
    "        # LightGBM\n",
    "   # y_lgb, lgb_opt = validate_lgb(X_train_v_ohe, X_train_v['Value'], X_valid_v_ohe, X_valid_v['Value'])\n",
    "   # y_lgb_mean, lgb_mean_opt = validate_lgb(X_train_v_meanenc, X_train_v['Value'], X_valid_v_meanenc, X_valid_v['Value'])\n",
    "   ## y_lgb_log, lgb_opt_log = validate_lgb(X_train_v_ohe, X_train_v['Value_log'], X_valid_v_ohe, X_valid_v['Value_log'])\n",
    "   # y_lgb_log = np.exp(y_lgb_log) -1\n",
    "   # y_lgb_mean_log, lgb_mean_opt_log = validate_lgb(X_train_v_meanenc, X_train_v['Value_log'], X_valid_v_meanenc, X_valid_v['Value_log'])\n",
    "   # y_lgb_mean_log = np.exp(y_lgb_mean_log) -1\n",
    "    \n",
    "    # stack predictions and make predictions \n",
    "    X_valid_stack = combine_y_hats([y_hat_grby_mean, y_hat_grby3_mean, \n",
    "                                    y_hat_grby_median, y_hat_grby3_median, \n",
    "                                    y_rf, y_rf_mean, \n",
    "                                    y_rf_log, y_rf_mean_log, \n",
    "                                   # y_lgb, y_lgb_mean, \n",
    "                                   # y_lgb_log, y_lgb_mean_log\n",
    "                                   ])\n",
    "    #y_rf_hat = validate_stack(X_valid_stack, X_valid_v['Value'], rf_stack)\n",
    "    y_lr_hat = cv_lr(X_valid_stack, X_valid_v['Value'], lr_stack)\n",
    " \n",
    "    # calculate scores and pick top model \n",
    "    iid = X_valid_v.reset_index()['index'] \n",
    "    T = np.max(iid)\n",
    "    index_mult = (3*T -2*iid +1) / 2 / T**2\n",
    "    \n",
    "    score_grby_mean = calc_score(y_hat_grby_mean, X_valid_v['Value'], index_mult)\n",
    "    score_grby3_mean = calc_score(y_hat_grby3_mean, X_valid_v['Value'], index_mult)\n",
    "    score_grby_median = calc_score(y_hat_grby_median, X_valid_v['Value'], index_mult)\n",
    "    score_grby3_median = calc_score(y_hat_grby3_median, X_valid_v['Value'], index_mult)\n",
    "    \n",
    "    score_rf = calc_score(y_rf, X_valid_v['Value'], index_mult)\n",
    "    score_rf_mean = calc_score(y_rf_mean, X_valid_v['Value'], index_mult)\n",
    "    score_rf_log = calc_score(y_rf_log, X_valid_v['Value'], index_mult)\n",
    "    score_rf_mean_log = calc_score(y_rf_mean_log, X_valid_v['Value'], index_mult)\n",
    "    \n",
    "    #score_lgb = calc_score(y_lgb, X_valid_v['Value'], index_mult)\n",
    "   ## score_lgb_mean = calc_score(y_lgb_mean, X_valid_v['Value'], index_mult)\n",
    "    #score_lgb_log = calc_score(y_lgb_log, X_valid_v['Value'], index_mult)\n",
    "   # score_lgb_mean_log = calc_score(y_lgb_mean_log, X_valid_v['Value'], index_mult)\n",
    "\n",
    "    score_lr_stack = calc_score(y_lr_hat, X_valid_v['Value'], index_mult)\n",
    "    \n",
    "    \n",
    "    y_hats     = [y_hat_grby_mean, y_hat_grby3_mean, \n",
    "                  y_hat_grby_median, y_hat_grby3_median, \n",
    "                  y_rf, y_rf_mean, \n",
    "                  y_rf_log, y_rf_mean_log, \n",
    "                 # y_lgb, y_lgb_mean, \n",
    "                 # y_lgb_log, y_lgb_mean_log, \n",
    "                  y_lr_hat\n",
    "                 ]\n",
    "    \n",
    "    all_scores = [score_grby_mean, score_grby3_mean, \n",
    "                  score_grby_median, score_grby3_median, \n",
    "                  score_rf, score_rf_mean, \n",
    "                  score_rf_log, score_rf_mean_log, \n",
    "                  #score_lgb, score_lgb_mean, \n",
    "                  #score_lgb_log, score_lgb_mean_log, \n",
    "                  score_lr_stack\n",
    "                 ]\n",
    "    \n",
    "    best_score = np.min(all_scores)\n",
    "    \n",
    "    models_names = ['mean_all', 'mean_3', \n",
    "                    'median_all', 'median_3', \n",
    "                    'rf', 'rf_mean', \n",
    "                    'rf_log', 'rf_mean_log', \n",
    "                   # 'lgb', 'lgb_mean', \n",
    "                   # 'lgb_log', 'lgb_mean_log', \n",
    "                    'lr_stack'\n",
    "                   ]\n",
    "    # plot figures and seve to folder \n",
    "    fig, ax = plt.subplots( nrows=1, ncols=1 )  # create figure & 1 axis\n",
    "    ax.plot(y_hats[np.argmin(all_scores)])\n",
    "    ax.plot(X_valid_v['Value'].reset_index(drop=True))\n",
    "    fig.savefig('pics/'+str(i)+'.jpg')   # save the figure to file\n",
    "    # plt.show()\n",
    "    plt.close(fig)    # close the figure\n",
    "    \n",
    "    # calc R2 and save later \n",
    "    r2 = r2_score(y_hats[np.argmin(all_scores)], X_valid_v['Value'] ) \n",
    "    losses.append( r2 )\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    print(i, 'Best model is', models_names[np.argmin(all_scores)], ' na value:', na_values_before, na_values_after)\n",
    "    print('loss:', r2 )\n",
    "    print(dict(zip(models_names, all_scores)))\n",
    "    print('-------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
